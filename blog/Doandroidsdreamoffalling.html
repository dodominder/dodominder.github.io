<!DOCTYPE html>
<html>
<head>
<link rel="shortcut icon" href="../images/favicon.ico" />
<link rel="stylesheet" href="../styles/style.css" />
<title>Dal9000</title>
</head>
<body>
<div class="navi">	
<ul>
  <li><a href="../index.html">Home</a></li>
  <li><a href="../blogs.html">Blog</a></li>
  <li><a href="../papers.html">Papers</a></li>
  <li><a href="../notes.html">Notes</a></li>
  <li><a href="../about.html">About</a></li>
</ul>
</div>

<div class="maintext">
<h1>Do androids dream of falling?</h1>
<p>
Without jumping too much into the details of why I'm writing this I'll just mention that I finished the first season of Westworld. An HBO series about a western theme park filled with androids that are indistinguishable from humans. Park guests do whatever they want to the robots without fear of being injured. The robots can't even harm a fly. When a guest tortures a robot you can almost feel it. The androids display all the signs of suffering. They get shot, cry, scream, and writhe in pain. They appear to suffer but is it real suffering? The show answers this question with an unequivocal YES but I don't see why the androids couldn't have been built to not suffer. These machines that can experience suffering go to sleep each night, get refurbished, to be propped back up in the park to the cruelest experiences the guests can think of. What makes this extra horrific is that it's all a game. An amusement.
</p><p>


Why do I think the robots can feel genuine suffering? What we'd call real suffering as opposed to fake suffering. I am not certain. Well not any more certain than when I assume that people around me genuinely suffer. How can I be certain that people close to me experience real suffering? I cannot be completely certain. Absolute certainty isn't something we ask when we question the truth or falsehood of the suffering of those that are close to us. I'm willing to accept the idea that a mind capable of experience is capable of experiencing suffering, whether the mind is made of neurons or bits.


</p><p>
Pain is a bit distinct from suffering. For someone born without the ability to feel pain may step on a piece of broken glass and bleed to death. They'd experience no pain in their foot but some suffering once they'd realized what was happening. This example makes me think it's possible to build androids indistinguishable from humans who can't feel pain. Just sever the lines that communicate pain. If the robot needed to act as if it were suffering then it still could imitate that response without actually getting the pain signal. The same as an actor who feigns pain when on stage without experiencing it.
</p><p>


To suffer though is a distinct thing from pain. A man thrown in jail who is told he will be shot in the foot and then the head the next day will experience suffering before ever feeling the pain brought from the bullets. Pain has its off switches but does suffering? The concept of suffering may be too ill-defined in my head for me to make sense of. Still I do not see why you couldn't make a human like machine that enjoyed its own suffering, if that makes any sense. Why were the androids in Westworld not constructed in such a way that they enjoyed suffering but still acted like they didn't? All the people in the TV show are actors who pretend to suffer. They don't experience real suffering and probably enjoy the experience of being on the show. If a real life theme park could be built like the one in Westworld then sentient androids should be constructed so that they thought of themselves as actors playing a role. A machine that can be built to suffer given a certain cause could be built not to suffer given the same cause.


</p><p>
The morality of building machines that can suffer brings us to the question of what an appropriate amount of suffering could be. Say that the problem of suffering is intractable given the constraints of engineering sentient minds. Given any sufficiently smart machine, it will have a capacity to suffer. There will be cases where this will be preferable to building such a machine to having not built it. Take, as an example, an android that was built to care for someone suffering from Alzheimer's disease. The machine could be made to feel the visceral pain of losing a loved one. It would take care of the patient as a loved one unto death. The android eases the suffering of the patient but the android itself would suffer. Is it moral to build this machine? I think so.
</p><p>


As stated before the capacity to suffer might be inescapable for a machine with sentience. And as my previous paragraph illustrates there will be cases where we minimize the total suffering by building the machine that suffers a little. In that vein it's tough to ask how much machine suffering is okay. Or how should suffering be measured? After five minutes of thinking about it I've discovered that the answer will take more than five minutes of thought. Perhaps we could measure suffering similar to the way we measure mineral hardness. Topaz is harder than iron because topaz can scrape iron but iron cannot scrape topaz. The items listed by their hardness are compared relative to each other as opposed to having some absolute scale. In a similar way we may say that this android suffers more than this man but less than this other android. Perhaps we'll discover the patterns of thought that create the experience of suffering. After which we could compare the patterns to some absolute standard of pure suffering and it's opposite, nonexistence.
</p><p>


My intuition in the case of an android is that if its sentience is built anything like that of a human's it would have the capacity to suffer that comes with being human. Having the capacity to suffer of course doesn't mean it will. Machines that can become as conscious as we are could become even more conscious than we are. To that end they could become more moral, more sensitive to pain, to suffering. Given their liability to greater pains and suffering its prudent to ask if we should even bother building such minds. That question hasn't stoped us from creating more people so I don't see why it would stop us from creating such androids.

</p>




</div>


</body>
</html>